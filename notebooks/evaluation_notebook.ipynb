{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb2c4196",
   "metadata": {},
   "source": [
    "### SCRIPT  1 MAKE_DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9457ff06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "##import seaborn as sns\n",
    "\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "\n",
    "# Preprocesar label\n",
    "from sklearn import preprocessing\n",
    "# Estandarizamos los datos\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# Normalizando los datos\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "\n",
    "# División de data entrenamiento y test\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "63de84c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leemos los archivos csv\n",
    "def read_file_excel(filename):\n",
    "    df = pd.read_excel(os.path.join('../data/raw/', filename), sheet_name = \"demomodifmodern2\", header = 0)\n",
    "    print(filename, ' cargado correctamente')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "75d8bc0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Realizamos la transformación de datos\n",
    "def data_preparation(df):\n",
    "    X = df.drop(['ingres'], axis=1)\n",
    "    y = df[['ingres']]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=101)\n",
    "    \n",
    "    dataset1 = X_train\n",
    "    dataset1['ingres']=y_train['ingres']\n",
    "    \n",
    "    #Métodos de detección de valores atípicos multivariante\n",
    "\n",
    "    #Se utilizará las variables\n",
    "    cols = ['ingres','Gastocoche','Aniosempleo']\n",
    "    \n",
    "    #Isolation Forests\n",
    "\n",
    "    clf=IsolationForest(n_estimators=100, max_samples='auto', contamination=0.01, \\\n",
    "                        max_features=3, bootstrap=False, n_jobs=-1, random_state=42, verbose=0)\n",
    "    clf.fit(dataset1[cols])\n",
    "    pred = clf.predict(dataset1[cols])\n",
    "    dataset1['anomaly']=pred\n",
    "    outliers_if=dataset1.loc[dataset1['anomaly']==-1]\n",
    "    outlier_if_index=list(outliers_if.index)\n",
    "    #print(outlier_index)\n",
    "    #print(dataset1['anomaly'].value_counts())\n",
    "    \n",
    "    #Métodos de detección de valores atípicos multivariante\n",
    "\n",
    "    #Se utilizará las variables\n",
    "    cols = ['ingres','edad','AniosDireccion']\n",
    "    \n",
    "    #Isolation Forests\n",
    "    dataset1_filtro1=dataset1.loc[dataset1['anomaly']==1].drop(['anomaly'], axis=1)\n",
    "\n",
    "\n",
    "    clf=IsolationForest(n_estimators=100, max_samples='auto', contamination=0.02, \\\n",
    "                        max_features=3, bootstrap=False, n_jobs=-1, random_state=42, verbose=0)\n",
    "    clf.fit(dataset1_filtro1[cols])\n",
    "    pred = clf.predict(dataset1_filtro1[cols])\n",
    "    dataset1_filtro1['anomaly_2']=pred\n",
    "    outliers_if=dataset1_filtro1.loc[dataset1_filtro1['anomaly_2']==-1]\n",
    "    outlier_if_index=list(outliers_if.index)\n",
    "    #print(outlier_index)\n",
    "    \n",
    "    #print(dataset1_filtro1['anomaly_2'].value_counts())\n",
    "    \n",
    "    dataset1_sinOutliers_vr2=dataset1_filtro1.loc[dataset1_filtro1['anomaly_2']==1].drop(['anomaly_2'], axis=1)\n",
    "    #dataset1.info()\n",
    "    #dataset1_sinOutliers_vr2.info()\n",
    "    \n",
    "    X_train_2 = dataset1_sinOutliers_vr2.drop(['ingres'], axis=1)\n",
    "    y_train_2 = dataset1_sinOutliers_vr2[['ingres']]\n",
    "    \n",
    "    data_train = X_train_2\n",
    "    data_train['ingres'] =  y_train_2\n",
    "    \n",
    "    data_test = X_test\n",
    "    data_test['ingres'] = y_test\n",
    "    \n",
    "    return data_train, data_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f2008831",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exportamos la matriz de datos con las columnas seleccionadas\n",
    "def data_exporting(df, filename):\n",
    "    df.to_csv(os.path.join('../data/raw/', filename))\n",
    "    print(filename, 'exportado correctamente en la carpeta raw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9887077c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Generamos las matrices de datos que se necesitan para la implementación\n",
    "\n",
    "def main():\n",
    "    \n",
    "    df = read_file_excel('rawdata-DataInferenciaIngresos.xlsx')\n",
    "    data_train, data_test = data_preparation(df)\n",
    "    \n",
    "    # Matriz de Entrenamiento\n",
    "    data_exporting(data_train, 'data_train.csv')\n",
    "    # Matriz de Validación\n",
    "    \n",
    "    data_exporting(data_test, 'data_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "de28ad87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rawdata-DataInferenciaIngresos.xlsx  cargado correctamente\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vdiaz\\miniconda3\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\vdiaz\\miniconda3\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_train.csv exportado correctamente en la carpeta raw\n",
      "data_test.csv exportado correctamente en la carpeta raw\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
